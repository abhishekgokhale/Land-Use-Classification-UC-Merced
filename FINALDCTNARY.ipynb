{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINALDCTNARY",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5-4vtRLMSag",
        "colab_type": "code",
        "outputId": "7ea45dfe-c582-4a62-d7db-ffc4f6632a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from PIL import Image #import Python Image Library\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxmUMmm7MXE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATADIR = '/content/drive/My Drive/UCMerced_LandUse/Images/'\n",
        "\n",
        "CATEGORIES = [ 'agricultural',  'airplane',    'baseballdiamond', 'beach',   'buildings',          'chaparral',         'denseresidential',\n",
        "                'forest',        'freeway',     'golfcourse',      'harbor',  'intersection',       'mediumresidential', 'mobilehomepark',\n",
        "                'overpass',      'parkinglot',  'river',           'runway',  'sparseresidential',  'storagetanks',      'tenniscourt' ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_H86fHPMfSX",
        "colab_type": "code",
        "outputId": "ac480c4c-0e16-4901-fae0-e8c1a0cff60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3RFKisIOJ50",
        "colab_type": "code",
        "outputId": "566c2797-4904-4642-fc8f-404c445b38c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "img_rows = 256\n",
        "img_cols = 256\n",
        "num_class = 21\n",
        "path = os.path.abspath('.cnn.py') #absolute path of program\n",
        "path = re.sub('[a-zA-Z\\s._]+$', '', path) #remove unintended file\n",
        "X = []\n",
        "Y = []\n",
        "dirs = os.listdir(path+'/drive/My Drive/ucmerced/UCMerced_LandUse/Images/')\n",
        "dirs=dirs[:-1]\n",
        "print(len(dirs))\n",
        "'''\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaAMcRQoRH4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = 0\n",
        "for i in dirs:\n",
        "\tn = 0\n",
        "\tcount = 0\n",
        "\tfor pic in glob.glob('/content/drive/My Drive/ucmerced/UCMerced_LandUse/Images/'+i+'/*.tif'):\n",
        "\t\tim = Image.open(pic)\n",
        "\t\tim = np.array(im)\n",
        "\t\tif((im.shape[0]==256) and (im.shape[1] ==256) ): #get only 90 data\n",
        "\t\t\tr = im[:,:,0]\n",
        "\t\t\tg = im[:,:,1]\n",
        "\t\t\tb = im[:,:,2]\n",
        "\t\t\tX.append([r,g,b])\n",
        "\t\t\tY.append([label])\n",
        "\tlabel = label + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTmBzCghOO8F",
        "colab_type": "code",
        "outputId": "b7921aea-cd75-492f-82fb-6e36546c0d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "x_bck=X\n",
        "y_bck=Y\n",
        "\n",
        "\n",
        "X =  np.array(X)\n",
        "Y =  np.array(Y)\n",
        "X = X.reshape(X.shape[0], img_rows, img_cols, 3)\n",
        "X.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2056, 256, 256, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LFYk6AVOaDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, 21)\n",
        "y_test = keras.utils.to_categorical(y_test, 21)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-GVSdwAfklB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "import cv2 \n",
        "from scipy.fftpack import dct \n",
        "\n",
        "a=[]\n",
        "b=[]\n",
        "#y = np.random.random((5000, 6, 6, 3))\n",
        "t1 = time.time()\n",
        "a = np.zeros((len(X_train), 256, 256, 3))\n",
        "b = np.zeros((len(X_test), 256, 256, 3))\n",
        "for i in range(len(X_train)):\n",
        "    for j in range(3):\n",
        "        a[i, : , : , j] = cv2.dct(X_train[i, : , : , j])\n",
        "        np.transpose(a, [0, 2, 1, 3])\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    for j in range(3):\n",
        "        a[i, :, :, j] = cv2.dct(X_train[i, :, :, j]) \n",
        "\n",
        "for i in range(0,len(X_test)):\n",
        "    for j in range(3):\n",
        "        b[i, : , : , j] = cv2.dct(X_test[i, : , : , j])\n",
        "        np.transpose(b, [0, 2, 1, 3])\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    for j in range(3):\n",
        "        b[i, :, :, j] = cv2.dct(X_test[i, :, :, j]) \n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igPtn4lQ2G20",
        "colab_type": "text"
      },
      "source": [
        "N_ARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J05M_EVd2Ij8",
        "colab_type": "code",
        "outputId": "280ce685-af71-42fc-9162-c50b28c7be9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1644, 256, 256, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvg4043k2QJZ",
        "colab_type": "code",
        "outputId": "2a7cb076-ca01-4aa0-c4e3-d2d829ea8997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(412, 256, 256, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iN3APuD84UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_cut = a[:,:64,:64,:]\n",
        "b_cut = b[:,:64,:64,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ8ERyLsFc-X",
        "colab_type": "code",
        "outputId": "fcdd9fc4-093c-4e61-d091-fa19e09e4fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "print(a_cut.shape)\n",
        "print(b_cut.shape)\n",
        "a_cut[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1644, 64, 64, 3)\n",
            "(412, 64, 64, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 1.47835556e+02,  1.47840195e+02,  1.47838654e+02],\n",
              "        [ 5.21849298e+00,  5.25082493e+00,  5.14235163e+00],\n",
              "        [ 5.70668429e-02, -6.38260171e-02, -9.71848443e-02],\n",
              "        ...,\n",
              "        [ 1.57773480e-01,  2.46358931e-01,  1.73625514e-01],\n",
              "        [ 5.07672653e-02,  5.09857535e-02, -7.54211321e-02],\n",
              "        [ 1.21159375e-01, -4.35238183e-02,  3.32568213e-02]],\n",
              "\n",
              "       [[ 2.81445265e+00,  2.82211614e+00,  2.81614518e+00],\n",
              "        [-1.88029975e-01, -1.29882589e-01, -2.28226602e-01],\n",
              "        [-1.61084607e-02, -3.25564444e-02, -4.90595996e-02],\n",
              "        ...,\n",
              "        [-1.92892194e-01, -1.60215259e-01, -2.25681633e-01],\n",
              "        [ 1.32334409e-02, -2.73033194e-02, -5.53416945e-02],\n",
              "        [-3.60127725e-02, -8.76026526e-02, -3.86507474e-02]],\n",
              "\n",
              "       [[-1.32274926e+00, -1.36632097e+00, -1.33996582e+00],\n",
              "        [ 2.19147369e-01,  2.35411420e-01,  1.95218042e-01],\n",
              "        [ 5.55694066e-02,  2.05401704e-02,  6.81882054e-02],\n",
              "        ...,\n",
              "        [-9.24402922e-02, -4.14222926e-02, -5.94179258e-02],\n",
              "        [ 4.98799831e-02,  1.85782984e-02, -6.68007657e-02],\n",
              "        [ 3.44357081e-03, -4.88422327e-02, -4.43770289e-02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-7.27096438e-01, -7.13704169e-01, -6.92256153e-01],\n",
              "        [-1.37619898e-02,  8.86595547e-02,  7.16895312e-02],\n",
              "        [-1.93780512e-01, -1.23576373e-01, -2.94151127e-01],\n",
              "        ...,\n",
              "        [ 1.29125729e-01,  8.62647742e-02,  1.53978258e-01],\n",
              "        [-1.13981187e-01, -1.44286692e-01,  8.20935294e-02],\n",
              "        [-1.26871318e-01,  7.60804117e-02,  9.11124423e-02]],\n",
              "\n",
              "       [[-1.37475282e-01, -9.31745991e-02, -9.56001431e-02],\n",
              "        [-1.34993717e-01, -7.24074095e-02, -1.14199281e-01],\n",
              "        [-1.32251233e-01, -4.66653556e-02, -1.64458066e-01],\n",
              "        ...,\n",
              "        [ 4.40632477e-02,  2.85935774e-02, -1.31819397e-05],\n",
              "        [ 1.05038583e-02, -6.77837059e-03,  4.76584695e-02],\n",
              "        [-4.95558903e-02,  1.04683498e-02,  7.58593390e-03]],\n",
              "\n",
              "       [[-4.37539756e-01, -4.35685873e-01, -4.61019337e-01],\n",
              "        [ 1.80302650e-01,  2.47163638e-01,  2.72660911e-01],\n",
              "        [-1.89639479e-01, -1.12748995e-01, -2.11875990e-01],\n",
              "        ...,\n",
              "        [-2.57413089e-03,  2.12468319e-02,  8.77769440e-02],\n",
              "        [ 1.21073211e-02, -8.33266228e-03,  3.10163712e-03],\n",
              "        [ 5.08603491e-02,  6.36543632e-02,  9.43393335e-02]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY7kvwQBFRx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_ary = a_cut.reshape((1644,4096,3))\n",
        "b_ary = b_cut.reshape((412,4096,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs3MispeapTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_ary_bckp=a_ary\n",
        "b_aray_bcp=b_ary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM7JsttMIdEj",
        "colab_type": "code",
        "outputId": "87e90023-8666-4984-9428-b787cffd8a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(a_ary.shape)\n",
        "a_ary[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1644, 4096, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.47835556e+02,  1.47840195e+02,  1.47838654e+02],\n",
              "       [ 5.21849298e+00,  5.25082493e+00,  5.14235163e+00],\n",
              "       [ 5.70668429e-02, -6.38260171e-02, -9.71848443e-02],\n",
              "       ...,\n",
              "       [-2.57413089e-03,  2.12468319e-02,  8.77769440e-02],\n",
              "       [ 1.21073211e-02, -8.33266228e-03,  3.10163712e-03],\n",
              "       [ 5.08603491e-02,  6.36543632e-02,  9.43393335e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntENNH9l-L_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_a_ary = np.zeros((a_ary.shape[0],4098,3))\n",
        "final_b_ary = np.zeros((b_ary.shape[0],4098,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xReGOVFi9yyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 2                                              #Change n for specific n-ary (n = anything in 2^n)\n",
        "mul=int(a_ary.shape[1])/n\n",
        "avgs = []\n",
        "count=0\n",
        "\n",
        "for j in range(a_ary.shape[0]):\n",
        "    avgR = []\n",
        "    avgG = []\n",
        "    avgB = []\n",
        "    for i in range(n):\n",
        "        l = int(mul*i)\n",
        "        lend = int(mul*(i+1) - 1)\n",
        "        np.sort(a_ary[j,:,0])\n",
        "        np.sort(a_ary[j,:,1])\n",
        "        np.sort(a_ary[j,:,2])\n",
        "        avgR.append(np.average(a_ary[j,l:lend,0]))\n",
        "        avgG.append(np.average(a_ary[j,l:lend,1]))\n",
        "        avgB.append(np.average(a_ary[j,l:lend,2]))\n",
        "    avgR = np.array(avgR)\n",
        "    avgG = np.array(avgG)\n",
        "    avgB = np.array(avgB)\n",
        "    final_a_ary[j,:,0] = np.concatenate((a_ary[j,:,0],avgR))\n",
        "    final_a_ary[j,:,1] = np.concatenate((a_ary[j,:,1],avgG))\n",
        "    final_a_ary[j,:,2] = np.concatenate((a_ary[j,:,2],avgB))\n",
        "\n",
        "mul=int(b_ary.shape[1])/n\n",
        "\n",
        "for j in range(b_ary.shape[0]):\n",
        "    avgR = []\n",
        "    avgG = []\n",
        "    avgB = []\n",
        "    for i in range(n):\n",
        "        l = int(mul*i)\n",
        "        lend = int(mul*(i+1) - 1)\n",
        "        np.sort(b_ary[j,:,0])\n",
        "        np.sort(b_ary[j,:,1])\n",
        "        np.sort(b_ary[j,:,2])\n",
        "        avgR.append(np.average(b_ary[j,l:lend,0]))\n",
        "        avgG.append(np.average(b_ary[j,l:lend,1]))\n",
        "        avgB.append(np.average(b_ary[j,l:lend,2]))\n",
        "    avgR = np.array(avgR)\n",
        "    avgG = np.array(avgG)\n",
        "    avgB = np.array(avgB)\n",
        "    final_b_ary[j,:,0] = np.concatenate((b_ary[j,:,0],avgR))\n",
        "    final_b_ary[j,:,1] = np.concatenate((b_ary[j,:,1],avgG))\n",
        "    final_b_ary[j,:,2] = np.concatenate((b_ary[j,:,2],avgB))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlhtGBgpwjES",
        "colab_type": "code",
        "outputId": "9c3ace53-0551-4598-e095-a2acf9bcd5c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "final_a_ary.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1644, 4098, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ucIItWQ8nVm",
        "colab_type": "code",
        "outputId": "02dc1af6-3350-470e-dd5b-5c4170e4a302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "final_b_ary.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(412, 4098, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVFSmG1H3o_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D, MaxPooling1D,Embedding\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import plot_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Graphic output\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqARZzJJEx9n",
        "colab_type": "text"
      },
      "source": [
        "**1DCNN ON MATRIX MIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LphFCo9kEw2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3m-MvF5E6Ua",
        "colab": {}
      },
      "source": [
        "model1dM = Sequential()\n",
        "model1dM.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
        "model1dM.add(MaxPooling1D(pool_size=(2)))\n",
        "model1dM.add(Conv1D(32, kernel_size=5))\n",
        "model1dM.add(MaxPooling1D(pool_size=(2)))\n",
        "model1dM.add(Conv1D(64, kernel_size=3))\n",
        "model1dM.add(MaxPooling1D(pool_size=(2)))\n",
        "model1dM.add(Dropout(0.25))\n",
        "model1dM.add(Flatten())\n",
        "model1dM.add(Dense(128, activation='relu',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
        "model1dM.add(Dropout(0.5))\n",
        "model1dM.add(Dense(21, activation='softmax'))\n",
        "model1dM.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ce872501-5b62-4e4e-8341-dea15ff6111f",
        "id": "lJqg5UKxE6Uh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "model1dM.fit(final_a_ary, y_train, batch_size=50, nb_epoch=20, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1644 samples, validate on 412 samples\n",
            "Epoch 1/20\n",
            "1644/1644 [==============================] - 2s 920us/step - loss: 8.2730 - accuracy: 0.1624 - val_loss: 3.4417 - val_accuracy: 0.3835\n",
            "Epoch 2/20\n",
            "1644/1644 [==============================] - 1s 651us/step - loss: 3.5044 - accuracy: 0.3279 - val_loss: 3.5040 - val_accuracy: 0.4417\n",
            "Epoch 3/20\n",
            "1644/1644 [==============================] - 1s 661us/step - loss: 3.5756 - accuracy: 0.3972 - val_loss: 3.4779 - val_accuracy: 0.4660\n",
            "Epoch 4/20\n",
            "1644/1644 [==============================] - 1s 664us/step - loss: 3.6264 - accuracy: 0.4063 - val_loss: 3.5341 - val_accuracy: 0.4757\n",
            "Epoch 5/20\n",
            "1644/1644 [==============================] - 1s 662us/step - loss: 3.5920 - accuracy: 0.4361 - val_loss: 3.6601 - val_accuracy: 0.4612\n",
            "Epoch 6/20\n",
            "1644/1644 [==============================] - 1s 668us/step - loss: 3.7955 - accuracy: 0.4726 - val_loss: 3.7814 - val_accuracy: 0.4612\n",
            "Epoch 7/20\n",
            "1644/1644 [==============================] - 1s 658us/step - loss: 3.8055 - accuracy: 0.4854 - val_loss: 3.8455 - val_accuracy: 0.5121\n",
            "Epoch 8/20\n",
            "1644/1644 [==============================] - 1s 638us/step - loss: 3.9094 - accuracy: 0.4860 - val_loss: 4.0543 - val_accuracy: 0.4903\n",
            "Epoch 9/20\n",
            "1644/1644 [==============================] - 1s 646us/step - loss: 4.1207 - accuracy: 0.5091 - val_loss: 4.1787 - val_accuracy: 0.4879\n",
            "Epoch 10/20\n",
            "1644/1644 [==============================] - 1s 645us/step - loss: 3.9462 - accuracy: 0.5462 - val_loss: 4.0495 - val_accuracy: 0.5364\n",
            "Epoch 11/20\n",
            "1644/1644 [==============================] - 1s 650us/step - loss: 3.8731 - accuracy: 0.5578 - val_loss: 4.0639 - val_accuracy: 0.5291\n",
            "Epoch 12/20\n",
            "1644/1644 [==============================] - 1s 659us/step - loss: 3.9633 - accuracy: 0.5773 - val_loss: 4.1605 - val_accuracy: 0.5680\n",
            "Epoch 13/20\n",
            "1644/1644 [==============================] - 1s 664us/step - loss: 3.9309 - accuracy: 0.6137 - val_loss: 4.2616 - val_accuracy: 0.5340\n",
            "Epoch 14/20\n",
            "1644/1644 [==============================] - 1s 658us/step - loss: 3.9262 - accuracy: 0.6210 - val_loss: 4.3118 - val_accuracy: 0.5510\n",
            "Epoch 15/20\n",
            "1644/1644 [==============================] - 1s 654us/step - loss: 4.1402 - accuracy: 0.6290 - val_loss: 4.5506 - val_accuracy: 0.5583\n",
            "Epoch 16/20\n",
            "1644/1644 [==============================] - 1s 644us/step - loss: 4.0742 - accuracy: 0.6442 - val_loss: 4.5354 - val_accuracy: 0.5218\n",
            "Epoch 17/20\n",
            "1644/1644 [==============================] - 1s 651us/step - loss: 4.0749 - accuracy: 0.6350 - val_loss: 4.1807 - val_accuracy: 0.5825\n",
            "Epoch 18/20\n",
            "1644/1644 [==============================] - 1s 649us/step - loss: 3.8695 - accuracy: 0.6490 - val_loss: 4.3940 - val_accuracy: 0.5510\n",
            "Epoch 19/20\n",
            "1644/1644 [==============================] - 1s 653us/step - loss: 4.0552 - accuracy: 0.6533 - val_loss: 4.3225 - val_accuracy: 0.5777\n",
            "Epoch 20/20\n",
            "1644/1644 [==============================] - 1s 649us/step - loss: 3.9938 - accuracy: 0.6405 - val_loss: 4.4045 - val_accuracy: 0.5752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f75d47ab278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "66309778-689b-4537-e209-e08bade31cd7",
        "id": "brf4w5dFE6Uq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, acc = model1dM.evaluate(final_b_ary, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing loss: 4.404512460949351, acc: 0.5752426981925964\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvEyN2vXF_-D",
        "colab_type": "text"
      },
      "source": [
        "**BATCH NORMALIZATION ON CONCATED MATRIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isxtNXF0GFRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d0634233-76bd-455f-ce83-11a749216a76",
        "id": "T1SmuLliGFkk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# instantiate model\n",
        "modelBNM = Sequential()\n",
        "modelBNM.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
        "modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNM.add(Conv1D(32, kernel_size=5))\n",
        "modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNM.add(Conv1D(64, kernel_size=3))\n",
        "modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNM.add(Dropout(0.25))\n",
        "modelBNM.add(Flatten())\n",
        "# we can think of this chunk as the input layer\n",
        "modelBNM.add(Dense(128,  init='uniform'))\n",
        "modelBNM.add(BatchNormalization())\n",
        "modelBNM.add(Activation('relu'))\n",
        "modelBNM.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the hidden layer    \n",
        "modelBNM.add(Dense(64, init='uniform'))\n",
        "modelBNM.add(BatchNormalization())\n",
        "modelBNM.add(Activation('relu'))\n",
        "modelBNM.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the output layer\n",
        "modelBNM.add(Dense(21, init='uniform'))\n",
        "modelBNM.add(BatchNormalization())\n",
        "modelBNM.add(Activation('softmax'))\n",
        "\n",
        "# setting up the optimization of our weights \n",
        "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "modelBNM.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# running the fitting\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_initializer=\"uniform\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_initializer=\"uniform\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(21, kernel_initializer=\"uniform\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2bb2abc4-1089-43a7-b085-98f9f7ba0d5a",
        "id": "o3eMMfiBGFkq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "modelBNM.fit(final_a_ary, y_train, batch_size=50, nb_epoch=30, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1644 samples, validate on 412 samples\n",
            "Epoch 1/30\n",
            " 250/1644 [===>..........................] - ETA: 1s - loss: 0.5776 - accuracy: 0.8960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1644/1644 [==============================] - 1s 742us/step - loss: 0.5633 - accuracy: 0.8978 - val_loss: 1.5373 - val_accuracy: 0.6141\n",
            "Epoch 2/30\n",
            "1644/1644 [==============================] - 1s 678us/step - loss: 0.5445 - accuracy: 0.9063 - val_loss: 1.5259 - val_accuracy: 0.6044\n",
            "Epoch 3/30\n",
            "1644/1644 [==============================] - 1s 682us/step - loss: 0.5327 - accuracy: 0.9161 - val_loss: 1.5611 - val_accuracy: 0.6068\n",
            "Epoch 4/30\n",
            "1644/1644 [==============================] - 1s 684us/step - loss: 0.5229 - accuracy: 0.9100 - val_loss: 1.5534 - val_accuracy: 0.5850\n",
            "Epoch 5/30\n",
            "1644/1644 [==============================] - 1s 676us/step - loss: 0.5234 - accuracy: 0.9106 - val_loss: 1.5376 - val_accuracy: 0.5971\n",
            "Epoch 6/30\n",
            "1644/1644 [==============================] - 1s 676us/step - loss: 0.5361 - accuracy: 0.8990 - val_loss: 1.5871 - val_accuracy: 0.5971\n",
            "Epoch 7/30\n",
            "1644/1644 [==============================] - 1s 683us/step - loss: 0.5100 - accuracy: 0.9124 - val_loss: 1.5486 - val_accuracy: 0.5922\n",
            "Epoch 8/30\n",
            "1644/1644 [==============================] - 1s 671us/step - loss: 0.4859 - accuracy: 0.9155 - val_loss: 1.5663 - val_accuracy: 0.5922\n",
            "Epoch 9/30\n",
            "1644/1644 [==============================] - 1s 671us/step - loss: 0.4712 - accuracy: 0.9142 - val_loss: 1.5879 - val_accuracy: 0.5971\n",
            "Epoch 10/30\n",
            "1644/1644 [==============================] - 1s 688us/step - loss: 0.4662 - accuracy: 0.9221 - val_loss: 1.5388 - val_accuracy: 0.6019\n",
            "Epoch 11/30\n",
            "1644/1644 [==============================] - 1s 691us/step - loss: 0.4674 - accuracy: 0.9300 - val_loss: 1.5388 - val_accuracy: 0.5922\n",
            "Epoch 12/30\n",
            "1644/1644 [==============================] - 1s 679us/step - loss: 0.4569 - accuracy: 0.9142 - val_loss: 1.5422 - val_accuracy: 0.5995\n",
            "Epoch 13/30\n",
            "1644/1644 [==============================] - 1s 676us/step - loss: 0.4929 - accuracy: 0.8984 - val_loss: 1.5646 - val_accuracy: 0.5898\n",
            "Epoch 14/30\n",
            "1644/1644 [==============================] - 1s 675us/step - loss: 0.4165 - accuracy: 0.9386 - val_loss: 1.5256 - val_accuracy: 0.5947\n",
            "Epoch 15/30\n",
            "1644/1644 [==============================] - 1s 669us/step - loss: 0.4145 - accuracy: 0.9392 - val_loss: 1.5197 - val_accuracy: 0.5971\n",
            "Epoch 16/30\n",
            "1644/1644 [==============================] - 1s 682us/step - loss: 0.4197 - accuracy: 0.9307 - val_loss: 1.5109 - val_accuracy: 0.5825\n",
            "Epoch 17/30\n",
            "1644/1644 [==============================] - 1s 687us/step - loss: 0.4022 - accuracy: 0.9337 - val_loss: 1.5242 - val_accuracy: 0.5874\n",
            "Epoch 18/30\n",
            "1644/1644 [==============================] - 1s 684us/step - loss: 0.3838 - accuracy: 0.9416 - val_loss: 1.5087 - val_accuracy: 0.6019\n",
            "Epoch 19/30\n",
            "1644/1644 [==============================] - 1s 687us/step - loss: 0.3519 - accuracy: 0.9562 - val_loss: 1.5130 - val_accuracy: 0.5898\n",
            "Epoch 20/30\n",
            "1644/1644 [==============================] - 1s 677us/step - loss: 0.3745 - accuracy: 0.9404 - val_loss: 1.5113 - val_accuracy: 0.5898\n",
            "Epoch 21/30\n",
            "1644/1644 [==============================] - 1s 691us/step - loss: 0.3924 - accuracy: 0.9361 - val_loss: 1.5447 - val_accuracy: 0.5801\n",
            "Epoch 22/30\n",
            "1644/1644 [==============================] - 1s 701us/step - loss: 0.3754 - accuracy: 0.9404 - val_loss: 1.5566 - val_accuracy: 0.6092\n",
            "Epoch 23/30\n",
            "1644/1644 [==============================] - 1s 686us/step - loss: 0.3987 - accuracy: 0.9367 - val_loss: 1.5078 - val_accuracy: 0.5995\n",
            "Epoch 24/30\n",
            "1644/1644 [==============================] - 1s 682us/step - loss: 0.3537 - accuracy: 0.9489 - val_loss: 1.5014 - val_accuracy: 0.6068\n",
            "Epoch 25/30\n",
            "1644/1644 [==============================] - 1s 676us/step - loss: 0.3766 - accuracy: 0.9300 - val_loss: 1.4990 - val_accuracy: 0.6044\n",
            "Epoch 26/30\n",
            "1644/1644 [==============================] - 1s 676us/step - loss: 0.3985 - accuracy: 0.9221 - val_loss: 1.5110 - val_accuracy: 0.5898\n",
            "Epoch 27/30\n",
            "1644/1644 [==============================] - 1s 670us/step - loss: 0.3728 - accuracy: 0.9355 - val_loss: 1.5401 - val_accuracy: 0.5898\n",
            "Epoch 28/30\n",
            "1644/1644 [==============================] - 1s 675us/step - loss: 0.3499 - accuracy: 0.9489 - val_loss: 1.4991 - val_accuracy: 0.5971\n",
            "Epoch 29/30\n",
            "1644/1644 [==============================] - 1s 670us/step - loss: 0.3501 - accuracy: 0.9355 - val_loss: 1.5156 - val_accuracy: 0.5947\n",
            "Epoch 30/30\n",
            "1644/1644 [==============================] - 1s 678us/step - loss: 0.3476 - accuracy: 0.9446 - val_loss: 1.5202 - val_accuracy: 0.5971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f75d379de48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fac78208-7278-46d8-dc8c-eaebdb524f62",
        "id": "GcbzxkeIGFkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, acc = modelBNM.evaluate(final_b_ary, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing loss: 1.520214778705708, acc: 0.5970873832702637\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpOSdZ7DHYmu",
        "colab_type": "text"
      },
      "source": [
        "**BN with regularization on matrix concat** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1_xJsLSHf4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bba979fe-3a62-4b1a-a317-e8e8dc0b6ac8",
        "id": "rxr7yO1hHgJ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# instantiate model\n",
        "modelBNrm = Sequential()\n",
        "modelBNrm.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
        "modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNrm.add(Conv1D(32, kernel_size=5))\n",
        "modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNrm.add(Conv1D(64, kernel_size=3))\n",
        "modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNrm.add(Dropout(0.25))\n",
        "modelBNrm.add(Flatten())\n",
        "# we can think of this chunk as the input layer\n",
        "modelBNrm.add(Dense(128,  init='uniform',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
        "modelBNrm.add(BatchNormalization())\n",
        "modelBNrm.add(Activation('relu'))\n",
        "modelBNrm.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the hidden layer    \n",
        "modelBNrm.add(Dense(64, init='uniform',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
        "modelBNrm.add(BatchNormalization())\n",
        "modelBNrm.add(Activation('relu'))\n",
        "modelBNrm.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the output layer\n",
        "modelBNrm.add(Dense(21, init='uniform',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
        "modelBNrm.add(BatchNormalization())\n",
        "modelBNrm.add(Activation('softmax'))\n",
        "\n",
        "# setting up the optimization of our weights \n",
        "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "modelBNrm.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# running the fitting\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_regularizer=<keras.reg..., kernel_initializer=\"uniform\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_regularizer=<keras.reg..., kernel_initializer=\"uniform\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(21, kernel_regularizer=<keras.reg..., kernel_initializer=\"uniform\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d8a3d079-8a2a-4ca7-85ab-79c40d5acf9a",
        "id": "nlTLXkUbHgKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "modelBNrm.fit(final_a_ary, y_train, batch_size=50, nb_epoch=150, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1644 samples, validate on 412 samples\n",
            "Epoch 1/150\n",
            " 150/1644 [=>............................] - ETA: 1s - loss: 4.6867 - accuracy: 0.5133"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1644/1644 [==============================] - 1s 795us/step - loss: 4.3868 - accuracy: 0.5268 - val_loss: 4.2876 - val_accuracy: 0.5485\n",
            "Epoch 2/150\n",
            "1644/1644 [==============================] - 1s 735us/step - loss: 4.3998 - accuracy: 0.5043 - val_loss: 4.6763 - val_accuracy: 0.5194\n",
            "Epoch 3/150\n",
            "1644/1644 [==============================] - 1s 713us/step - loss: 4.5110 - accuracy: 0.5109 - val_loss: 4.6828 - val_accuracy: 0.5267\n",
            "Epoch 4/150\n",
            "1644/1644 [==============================] - 1s 705us/step - loss: 4.4550 - accuracy: 0.4915 - val_loss: 4.5223 - val_accuracy: 0.5801\n",
            "Epoch 5/150\n",
            "1644/1644 [==============================] - 1s 699us/step - loss: 4.4064 - accuracy: 0.5164 - val_loss: 4.5417 - val_accuracy: 0.5704\n",
            "Epoch 6/150\n",
            "1644/1644 [==============================] - 1s 705us/step - loss: 4.4523 - accuracy: 0.5456 - val_loss: 4.4816 - val_accuracy: 0.5461\n",
            "Epoch 7/150\n",
            "1644/1644 [==============================] - 1s 702us/step - loss: 4.3098 - accuracy: 0.5341 - val_loss: 4.6020 - val_accuracy: 0.5049\n",
            "Epoch 8/150\n",
            "1644/1644 [==============================] - 1s 714us/step - loss: 4.4802 - accuracy: 0.5116 - val_loss: 4.6188 - val_accuracy: 0.5971\n",
            "Epoch 9/150\n",
            "1644/1644 [==============================] - 1s 711us/step - loss: 4.3564 - accuracy: 0.5280 - val_loss: 4.5067 - val_accuracy: 0.5413\n",
            "Epoch 10/150\n",
            "1644/1644 [==============================] - 1s 708us/step - loss: 4.6463 - accuracy: 0.5109 - val_loss: 4.5085 - val_accuracy: 0.5340\n",
            "Epoch 11/150\n",
            "1644/1644 [==============================] - 1s 709us/step - loss: 4.3702 - accuracy: 0.5262 - val_loss: 4.8665 - val_accuracy: 0.5510\n",
            "Epoch 12/150\n",
            "1644/1644 [==============================] - 1s 715us/step - loss: 4.6841 - accuracy: 0.5481 - val_loss: 4.8008 - val_accuracy: 0.5437\n",
            "Epoch 13/150\n",
            "1644/1644 [==============================] - 1s 728us/step - loss: 4.6953 - accuracy: 0.5347 - val_loss: 4.7364 - val_accuracy: 0.5558\n",
            "Epoch 14/150\n",
            "1644/1644 [==============================] - 1s 711us/step - loss: 4.7404 - accuracy: 0.5036 - val_loss: 4.7265 - val_accuracy: 0.4927\n",
            "Epoch 15/150\n",
            "1644/1644 [==============================] - 1s 720us/step - loss: 4.6611 - accuracy: 0.5554 - val_loss: 4.8453 - val_accuracy: 0.5850\n",
            "Epoch 16/150\n",
            "1644/1644 [==============================] - 1s 725us/step - loss: 4.8199 - accuracy: 0.5310 - val_loss: 4.7269 - val_accuracy: 0.5728\n",
            "Epoch 17/150\n",
            "1644/1644 [==============================] - 1s 700us/step - loss: 4.5480 - accuracy: 0.5408 - val_loss: 4.8792 - val_accuracy: 0.5801\n",
            "Epoch 18/150\n",
            "1644/1644 [==============================] - 1s 708us/step - loss: 4.6661 - accuracy: 0.5651 - val_loss: 4.8751 - val_accuracy: 0.5704\n",
            "Epoch 19/150\n",
            "1644/1644 [==============================] - 1s 709us/step - loss: 4.7061 - accuracy: 0.5274 - val_loss: 4.9293 - val_accuracy: 0.5655\n",
            "Epoch 20/150\n",
            "1644/1644 [==============================] - 1s 699us/step - loss: 4.7567 - accuracy: 0.5523 - val_loss: 5.0028 - val_accuracy: 0.5558\n",
            "Epoch 21/150\n",
            "1644/1644 [==============================] - 1s 710us/step - loss: 4.5824 - accuracy: 0.5797 - val_loss: 4.7862 - val_accuracy: 0.5510\n",
            "Epoch 22/150\n",
            "1644/1644 [==============================] - 1s 714us/step - loss: 4.7901 - accuracy: 0.5420 - val_loss: 5.2894 - val_accuracy: 0.5364\n",
            "Epoch 23/150\n",
            "1644/1644 [==============================] - 1s 721us/step - loss: 4.9264 - accuracy: 0.5505 - val_loss: 4.7678 - val_accuracy: 0.5583\n",
            "Epoch 24/150\n",
            "1644/1644 [==============================] - 1s 715us/step - loss: 4.5910 - accuracy: 0.5730 - val_loss: 4.6398 - val_accuracy: 0.5680\n",
            "Epoch 25/150\n",
            "1644/1644 [==============================] - 1s 736us/step - loss: 4.6799 - accuracy: 0.5639 - val_loss: 4.9423 - val_accuracy: 0.5194\n",
            "Epoch 26/150\n",
            "1644/1644 [==============================] - 1s 703us/step - loss: 4.7350 - accuracy: 0.5535 - val_loss: 4.9189 - val_accuracy: 0.5704\n",
            "Epoch 27/150\n",
            "1644/1644 [==============================] - 1s 699us/step - loss: 4.8289 - accuracy: 0.5554 - val_loss: 4.9079 - val_accuracy: 0.5631\n",
            "Epoch 28/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 4.6813 - accuracy: 0.5785 - val_loss: 4.8701 - val_accuracy: 0.5777\n",
            "Epoch 29/150\n",
            "1644/1644 [==============================] - 1s 702us/step - loss: 4.7849 - accuracy: 0.5657 - val_loss: 5.0439 - val_accuracy: 0.5558\n",
            "Epoch 30/150\n",
            "1644/1644 [==============================] - 1s 718us/step - loss: 4.9257 - accuracy: 0.5395 - val_loss: 5.0292 - val_accuracy: 0.5243\n",
            "Epoch 31/150\n",
            "1644/1644 [==============================] - 1s 727us/step - loss: 4.7546 - accuracy: 0.5614 - val_loss: 4.9525 - val_accuracy: 0.5583\n",
            "Epoch 32/150\n",
            "1644/1644 [==============================] - 1s 703us/step - loss: 4.9761 - accuracy: 0.5620 - val_loss: 5.5304 - val_accuracy: 0.5340\n",
            "Epoch 33/150\n",
            "1644/1644 [==============================] - 1s 697us/step - loss: 5.0937 - accuracy: 0.5742 - val_loss: 5.1906 - val_accuracy: 0.5922\n",
            "Epoch 34/150\n",
            "1644/1644 [==============================] - 1s 716us/step - loss: 4.9116 - accuracy: 0.5827 - val_loss: 5.0086 - val_accuracy: 0.5267\n",
            "Epoch 35/150\n",
            "1644/1644 [==============================] - 1s 708us/step - loss: 4.8817 - accuracy: 0.5657 - val_loss: 4.9863 - val_accuracy: 0.5704\n",
            "Epoch 36/150\n",
            "1644/1644 [==============================] - 1s 707us/step - loss: 4.7407 - accuracy: 0.5815 - val_loss: 4.8469 - val_accuracy: 0.5558\n",
            "Epoch 37/150\n",
            "1644/1644 [==============================] - 1s 708us/step - loss: 4.9141 - accuracy: 0.5687 - val_loss: 5.3467 - val_accuracy: 0.5558\n",
            "Epoch 38/150\n",
            "1644/1644 [==============================] - 1s 700us/step - loss: 4.9735 - accuracy: 0.5839 - val_loss: 5.0162 - val_accuracy: 0.5631\n",
            "Epoch 39/150\n",
            "1644/1644 [==============================] - 1s 709us/step - loss: 4.7212 - accuracy: 0.5998 - val_loss: 5.1243 - val_accuracy: 0.5316\n",
            "Epoch 40/150\n",
            "1644/1644 [==============================] - 1s 711us/step - loss: 5.0585 - accuracy: 0.5620 - val_loss: 5.0954 - val_accuracy: 0.5752\n",
            "Epoch 41/150\n",
            "1644/1644 [==============================] - 1s 723us/step - loss: 4.9443 - accuracy: 0.5639 - val_loss: 5.0230 - val_accuracy: 0.5291\n",
            "Epoch 42/150\n",
            "1644/1644 [==============================] - 1s 718us/step - loss: 4.7828 - accuracy: 0.5937 - val_loss: 4.8711 - val_accuracy: 0.5243\n",
            "Epoch 43/150\n",
            "1644/1644 [==============================] - 1s 722us/step - loss: 4.5986 - accuracy: 0.5693 - val_loss: 4.9760 - val_accuracy: 0.5607\n",
            "Epoch 44/150\n",
            "1644/1644 [==============================] - 1s 711us/step - loss: 4.9683 - accuracy: 0.5718 - val_loss: 5.0524 - val_accuracy: 0.5243\n",
            "Epoch 45/150\n",
            "1644/1644 [==============================] - 1s 716us/step - loss: 4.8557 - accuracy: 0.5961 - val_loss: 5.3856 - val_accuracy: 0.5413\n",
            "Epoch 46/150\n",
            "1644/1644 [==============================] - 1s 701us/step - loss: 4.9845 - accuracy: 0.5991 - val_loss: 5.0122 - val_accuracy: 0.5801\n",
            "Epoch 47/150\n",
            "1644/1644 [==============================] - 1s 704us/step - loss: 4.9035 - accuracy: 0.5864 - val_loss: 5.1247 - val_accuracy: 0.5728\n",
            "Epoch 48/150\n",
            "1644/1644 [==============================] - 1s 716us/step - loss: 4.8971 - accuracy: 0.6204 - val_loss: 5.4511 - val_accuracy: 0.5631\n",
            "Epoch 49/150\n",
            "1644/1644 [==============================] - 1s 717us/step - loss: 5.0625 - accuracy: 0.5730 - val_loss: 5.3182 - val_accuracy: 0.5073\n",
            "Epoch 50/150\n",
            "1644/1644 [==============================] - 1s 709us/step - loss: 4.9558 - accuracy: 0.5852 - val_loss: 5.1164 - val_accuracy: 0.5752\n",
            "Epoch 51/150\n",
            "1644/1644 [==============================] - 1s 711us/step - loss: 4.9394 - accuracy: 0.5839 - val_loss: 5.0931 - val_accuracy: 0.5388\n",
            "Epoch 52/150\n",
            "1644/1644 [==============================] - 1s 718us/step - loss: 4.8920 - accuracy: 0.5985 - val_loss: 4.9356 - val_accuracy: 0.5510\n",
            "Epoch 53/150\n",
            "1644/1644 [==============================] - 1s 705us/step - loss: 4.8297 - accuracy: 0.5918 - val_loss: 5.1600 - val_accuracy: 0.5558\n",
            "Epoch 54/150\n",
            "1644/1644 [==============================] - 1s 725us/step - loss: 4.9518 - accuracy: 0.5937 - val_loss: 5.0207 - val_accuracy: 0.5704\n",
            "Epoch 55/150\n",
            "1644/1644 [==============================] - 1s 713us/step - loss: 4.9878 - accuracy: 0.5888 - val_loss: 5.2957 - val_accuracy: 0.5194\n",
            "Epoch 56/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 4.8362 - accuracy: 0.5967 - val_loss: 5.1781 - val_accuracy: 0.5340\n",
            "Epoch 57/150\n",
            "1644/1644 [==============================] - 1s 702us/step - loss: 4.9310 - accuracy: 0.6004 - val_loss: 5.1547 - val_accuracy: 0.5825\n",
            "Epoch 58/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 5.0888 - accuracy: 0.5955 - val_loss: 5.1452 - val_accuracy: 0.5631\n",
            "Epoch 59/150\n",
            "1644/1644 [==============================] - 1s 702us/step - loss: 4.9067 - accuracy: 0.6016 - val_loss: 5.1961 - val_accuracy: 0.5655\n",
            "Epoch 60/150\n",
            "1644/1644 [==============================] - 1s 730us/step - loss: 4.9263 - accuracy: 0.5979 - val_loss: 5.2288 - val_accuracy: 0.5437\n",
            "Epoch 61/150\n",
            "1644/1644 [==============================] - 1s 734us/step - loss: 5.3197 - accuracy: 0.5900 - val_loss: 5.5859 - val_accuracy: 0.5243\n",
            "Epoch 62/150\n",
            "1644/1644 [==============================] - 1s 731us/step - loss: 5.0143 - accuracy: 0.6119 - val_loss: 5.1806 - val_accuracy: 0.5510\n",
            "Epoch 63/150\n",
            "1644/1644 [==============================] - 1s 735us/step - loss: 4.7684 - accuracy: 0.6363 - val_loss: 5.1906 - val_accuracy: 0.5340\n",
            "Epoch 64/150\n",
            "1644/1644 [==============================] - 1s 737us/step - loss: 5.0732 - accuracy: 0.5991 - val_loss: 5.2299 - val_accuracy: 0.5558\n",
            "Epoch 65/150\n",
            "1644/1644 [==============================] - 1s 715us/step - loss: 5.0025 - accuracy: 0.6046 - val_loss: 5.3128 - val_accuracy: 0.5316\n",
            "Epoch 66/150\n",
            "1644/1644 [==============================] - 1s 721us/step - loss: 4.7563 - accuracy: 0.6204 - val_loss: 5.0050 - val_accuracy: 0.5801\n",
            "Epoch 67/150\n",
            "1644/1644 [==============================] - 1s 705us/step - loss: 5.0661 - accuracy: 0.6046 - val_loss: 5.3712 - val_accuracy: 0.5413\n",
            "Epoch 68/150\n",
            "1644/1644 [==============================] - 1s 702us/step - loss: 5.2480 - accuracy: 0.5858 - val_loss: 5.5152 - val_accuracy: 0.5801\n",
            "Epoch 69/150\n",
            "1644/1644 [==============================] - 1s 726us/step - loss: 5.0864 - accuracy: 0.6144 - val_loss: 5.1369 - val_accuracy: 0.5607\n",
            "Epoch 70/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 4.8005 - accuracy: 0.6241 - val_loss: 5.2850 - val_accuracy: 0.5558\n",
            "Epoch 71/150\n",
            "1644/1644 [==============================] - 1s 701us/step - loss: 5.0520 - accuracy: 0.6107 - val_loss: 5.6359 - val_accuracy: 0.5194\n",
            "Epoch 72/150\n",
            "1644/1644 [==============================] - 1s 700us/step - loss: 5.1730 - accuracy: 0.6204 - val_loss: 5.1100 - val_accuracy: 0.5655\n",
            "Epoch 73/150\n",
            "1644/1644 [==============================] - 1s 702us/step - loss: 5.0159 - accuracy: 0.5979 - val_loss: 5.4346 - val_accuracy: 0.5534\n",
            "Epoch 74/150\n",
            "1644/1644 [==============================] - 1s 703us/step - loss: 5.2485 - accuracy: 0.5937 - val_loss: 5.3698 - val_accuracy: 0.5583\n",
            "Epoch 75/150\n",
            "1644/1644 [==============================] - 1s 722us/step - loss: 4.9662 - accuracy: 0.5973 - val_loss: 5.4416 - val_accuracy: 0.5437\n",
            "Epoch 76/150\n",
            "1644/1644 [==============================] - 1s 724us/step - loss: 5.0389 - accuracy: 0.6247 - val_loss: 5.1639 - val_accuracy: 0.5461\n",
            "Epoch 77/150\n",
            "1644/1644 [==============================] - 1s 697us/step - loss: 5.1207 - accuracy: 0.5949 - val_loss: 5.6055 - val_accuracy: 0.5437\n",
            "Epoch 78/150\n",
            "1644/1644 [==============================] - 1s 716us/step - loss: 5.1594 - accuracy: 0.6137 - val_loss: 5.1843 - val_accuracy: 0.5485\n",
            "Epoch 79/150\n",
            "1644/1644 [==============================] - 1s 710us/step - loss: 4.7798 - accuracy: 0.6150 - val_loss: 5.1061 - val_accuracy: 0.5922\n",
            "Epoch 80/150\n",
            "1644/1644 [==============================] - 1s 707us/step - loss: 4.8476 - accuracy: 0.6356 - val_loss: 4.9947 - val_accuracy: 0.5680\n",
            "Epoch 81/150\n",
            "1644/1644 [==============================] - 1s 705us/step - loss: 4.8779 - accuracy: 0.6308 - val_loss: 5.2879 - val_accuracy: 0.6068\n",
            "Epoch 82/150\n",
            "1644/1644 [==============================] - 1s 699us/step - loss: 5.3098 - accuracy: 0.6058 - val_loss: 5.5343 - val_accuracy: 0.5194\n",
            "Epoch 83/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 4.9734 - accuracy: 0.6162 - val_loss: 4.8915 - val_accuracy: 0.5534\n",
            "Epoch 84/150\n",
            "1644/1644 [==============================] - 1s 704us/step - loss: 4.9940 - accuracy: 0.6271 - val_loss: 5.6748 - val_accuracy: 0.5558\n",
            "Epoch 85/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 5.2976 - accuracy: 0.6186 - val_loss: 5.4178 - val_accuracy: 0.5583\n",
            "Epoch 86/150\n",
            "1644/1644 [==============================] - 1s 731us/step - loss: 5.0864 - accuracy: 0.5979 - val_loss: 5.1433 - val_accuracy: 0.5777\n",
            "Epoch 87/150\n",
            "1644/1644 [==============================] - 1s 713us/step - loss: 4.8797 - accuracy: 0.6016 - val_loss: 5.4663 - val_accuracy: 0.5437\n",
            "Epoch 88/150\n",
            "1644/1644 [==============================] - 1s 704us/step - loss: 5.4076 - accuracy: 0.6253 - val_loss: 5.3986 - val_accuracy: 0.5825\n",
            "Epoch 89/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 4.9613 - accuracy: 0.6229 - val_loss: 5.3625 - val_accuracy: 0.5680\n",
            "Epoch 90/150\n",
            "1644/1644 [==============================] - 1s 711us/step - loss: 5.0991 - accuracy: 0.6186 - val_loss: 5.4817 - val_accuracy: 0.5485\n",
            "Epoch 91/150\n",
            "1644/1644 [==============================] - 1s 702us/step - loss: 5.1033 - accuracy: 0.6332 - val_loss: 5.5796 - val_accuracy: 0.5316\n",
            "Epoch 92/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 5.1669 - accuracy: 0.6393 - val_loss: 5.4147 - val_accuracy: 0.5316\n",
            "Epoch 93/150\n",
            "1644/1644 [==============================] - 1s 713us/step - loss: 4.8137 - accuracy: 0.6241 - val_loss: 5.1668 - val_accuracy: 0.5558\n",
            "Epoch 94/150\n",
            "1644/1644 [==============================] - 1s 706us/step - loss: 5.1157 - accuracy: 0.6162 - val_loss: 5.2334 - val_accuracy: 0.5194\n",
            "Epoch 95/150\n",
            "1644/1644 [==============================] - 1s 714us/step - loss: 5.1501 - accuracy: 0.6314 - val_loss: 5.5101 - val_accuracy: 0.5558\n",
            "Epoch 96/150\n",
            "1644/1644 [==============================] - 1s 724us/step - loss: 4.8253 - accuracy: 0.6314 - val_loss: 5.1813 - val_accuracy: 0.5316\n",
            "Epoch 97/150\n",
            " 650/1644 [==========>...................] - ETA: 0s - loss: 5.0631 - accuracy: 0.6492"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-f928282ff135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelBNrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_a_ary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_b_ary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b69a58bc-0ce9-4376-cbec-5291bf20dfc5",
        "id": "FQqWMQiwHgKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, acc = modelBNrm.evaluate(final_b_ary, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing loss: 4.510797898746231, acc: 0.49757280945777893\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mo8OnblIcJ_",
        "colab_type": "text"
      },
      "source": [
        "BATCH NORMALIZATION ON CNN LAYERS WITH MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9f569747-433d-4586-f6b3-106871bd7d80",
        "id": "8EeQbskmIg33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# instantiate model\n",
        "modelBNC = Sequential()\n",
        "modelBNC.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNC.add(Conv1D(32, kernel_size=5))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNC.add(Conv1D(64, kernel_size=3))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNC.add(Dropout(0.25))\n",
        "modelBNC.add(Flatten())\n",
        "# we can think of this chunk as the input layer\n",
        "modelBNC.add(Dense(128, init='uniform'))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(Activation('relu'))\n",
        "modelBNC.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the hidden layer    \n",
        "modelBNC.add(Dense(64, init='uniform'))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(Activation('relu'))\n",
        "modelBNC.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the output layer\n",
        "modelBNC.add(Dense(21, init='uniform'))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(Activation('softmax'))\n",
        "\n",
        "# setting up the optimization of our weights \n",
        "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#modelBNC.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "modelBNC.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# running the fitting\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_initializer=\"uniform\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_initializer=\"uniform\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(21, kernel_initializer=\"uniform\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c1b5749c-1b54-4dda-a48c-a81d1c80c0c5",
        "id": "ks9Zw_B9Ig4A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "modelBNC.fit(final_a_ary, y_train, batch_size=50, nb_epoch=30, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1644 samples, validate on 412 samples\n",
            "Epoch 1/30\n",
            "1644/1644 [==============================] - 3s 2ms/step - loss: 2.8930 - accuracy: 0.1429 - val_loss: 2.9518 - val_accuracy: 0.3010\n",
            "Epoch 2/30\n",
            "1644/1644 [==============================] - 2s 975us/step - loss: 2.3889 - accuracy: 0.2616 - val_loss: 2.9040 - val_accuracy: 0.3131\n",
            "Epoch 3/30\n",
            "1644/1644 [==============================] - 2s 985us/step - loss: 2.1941 - accuracy: 0.3437 - val_loss: 2.8549 - val_accuracy: 0.2913\n",
            "Epoch 4/30\n",
            "1644/1644 [==============================] - 2s 995us/step - loss: 1.9910 - accuracy: 0.4422 - val_loss: 2.7610 - val_accuracy: 0.2985\n",
            "Epoch 5/30\n",
            "1644/1644 [==============================] - 2s 987us/step - loss: 1.8875 - accuracy: 0.4708 - val_loss: 2.6815 - val_accuracy: 0.3083\n",
            "Epoch 6/30\n",
            "1644/1644 [==============================] - 2s 976us/step - loss: 1.7754 - accuracy: 0.5219 - val_loss: 2.5890 - val_accuracy: 0.3277\n",
            "Epoch 7/30\n",
            "1644/1644 [==============================] - 2s 979us/step - loss: 1.6395 - accuracy: 0.5827 - val_loss: 2.4790 - val_accuracy: 0.3471\n",
            "Epoch 8/30\n",
            "1644/1644 [==============================] - 2s 982us/step - loss: 1.5628 - accuracy: 0.5925 - val_loss: 2.3529 - val_accuracy: 0.4345\n",
            "Epoch 9/30\n",
            "1644/1644 [==============================] - 2s 978us/step - loss: 1.4488 - accuracy: 0.6417 - val_loss: 2.1267 - val_accuracy: 0.4830\n",
            "Epoch 10/30\n",
            "1644/1644 [==============================] - 2s 978us/step - loss: 1.3720 - accuracy: 0.6691 - val_loss: 2.0586 - val_accuracy: 0.4976\n",
            "Epoch 11/30\n",
            "1644/1644 [==============================] - 2s 978us/step - loss: 1.2892 - accuracy: 0.7050 - val_loss: 1.9563 - val_accuracy: 0.5316\n",
            "Epoch 12/30\n",
            "1644/1644 [==============================] - 2s 986us/step - loss: 1.2173 - accuracy: 0.7202 - val_loss: 1.8612 - val_accuracy: 0.5558\n",
            "Epoch 13/30\n",
            "1644/1644 [==============================] - 2s 979us/step - loss: 1.1680 - accuracy: 0.7153 - val_loss: 1.8627 - val_accuracy: 0.5267\n",
            "Epoch 14/30\n",
            "1644/1644 [==============================] - 2s 983us/step - loss: 1.0761 - accuracy: 0.7561 - val_loss: 1.7236 - val_accuracy: 0.5704\n",
            "Epoch 15/30\n",
            "1644/1644 [==============================] - 2s 983us/step - loss: 1.0318 - accuracy: 0.7713 - val_loss: 1.7196 - val_accuracy: 0.5534\n",
            "Epoch 16/30\n",
            "1644/1644 [==============================] - 2s 995us/step - loss: 0.9727 - accuracy: 0.8035 - val_loss: 1.7251 - val_accuracy: 0.5534\n",
            "Epoch 17/30\n",
            "1644/1644 [==============================] - 2s 988us/step - loss: 0.9353 - accuracy: 0.8078 - val_loss: 1.6883 - val_accuracy: 0.5752\n",
            "Epoch 18/30\n",
            "1644/1644 [==============================] - 2s 986us/step - loss: 0.8792 - accuracy: 0.8327 - val_loss: 1.6726 - val_accuracy: 0.5558\n",
            "Epoch 19/30\n",
            "1644/1644 [==============================] - 2s 987us/step - loss: 0.8435 - accuracy: 0.8418 - val_loss: 1.6392 - val_accuracy: 0.5728\n",
            "Epoch 20/30\n",
            "1644/1644 [==============================] - 2s 979us/step - loss: 0.7999 - accuracy: 0.8540 - val_loss: 1.5864 - val_accuracy: 0.5995\n",
            "Epoch 21/30\n",
            "1644/1644 [==============================] - 2s 980us/step - loss: 0.7795 - accuracy: 0.8662 - val_loss: 1.5782 - val_accuracy: 0.5971\n",
            "Epoch 22/30\n",
            "1644/1644 [==============================] - 2s 981us/step - loss: 0.7525 - accuracy: 0.8729 - val_loss: 1.6278 - val_accuracy: 0.5825\n",
            "Epoch 23/30\n",
            "1644/1644 [==============================] - 2s 985us/step - loss: 0.7013 - accuracy: 0.8765 - val_loss: 1.6088 - val_accuracy: 0.5801\n",
            "Epoch 24/30\n",
            "1644/1644 [==============================] - 2s 978us/step - loss: 0.7018 - accuracy: 0.8723 - val_loss: 1.5907 - val_accuracy: 0.5898\n",
            "Epoch 25/30\n",
            "1644/1644 [==============================] - 2s 989us/step - loss: 0.6764 - accuracy: 0.8863 - val_loss: 1.5726 - val_accuracy: 0.6044\n",
            "Epoch 26/30\n",
            "1644/1644 [==============================] - 2s 989us/step - loss: 0.6264 - accuracy: 0.9027 - val_loss: 1.6291 - val_accuracy: 0.5752\n",
            "Epoch 27/30\n",
            "1644/1644 [==============================] - 2s 989us/step - loss: 0.6229 - accuracy: 0.8978 - val_loss: 1.5537 - val_accuracy: 0.6068\n",
            "Epoch 28/30\n",
            "1644/1644 [==============================] - 2s 982us/step - loss: 0.6462 - accuracy: 0.8802 - val_loss: 1.5852 - val_accuracy: 0.5704\n",
            "Epoch 29/30\n",
            "1644/1644 [==============================] - 2s 990us/step - loss: 0.5686 - accuracy: 0.9155 - val_loss: 1.5659 - val_accuracy: 0.6044\n",
            "Epoch 30/30\n",
            "1644/1644 [==============================] - 2s 996us/step - loss: 0.5814 - accuracy: 0.9002 - val_loss: 1.5777 - val_accuracy: 0.5874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f38aac77780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "46821a7d-b37c-4a8e-c569-da6d341d6b1f",
        "id": "odKwdMviIg4F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, acc = modelBNC.evaluate(final_b_ary, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing loss: 1.5777395766915627, acc: 0.5873786211013794\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}