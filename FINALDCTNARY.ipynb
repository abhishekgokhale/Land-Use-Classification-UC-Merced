{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINALDCTNARY_Abhishek.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5-4vtRLMSag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from PIL import Image #import Python Image Library\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxmUMmm7MXE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATADIR = '/content/drive/My Drive/UCMerced_LandUse/Images/'\n",
        "\n",
        "CATEGORIES = [ 'agricultural',  'airplane',    'baseballdiamond', 'beach',   'buildings',          'chaparral',         'denseresidential',\n",
        "                'forest',        'freeway',     'golfcourse',      'harbor',  'intersection',       'mediumresidential', 'mobilehomepark',\n",
        "                'overpass',      'parkinglot',  'river',           'runway',  'sparseresidential',  'storagetanks',      'tenniscourt' ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_H86fHPMfSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3RFKisIOJ50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 256\n",
        "img_cols = 256\n",
        "num_class = 21\n",
        "path = os.path.abspath('.cnn.py') #absolute path of program\n",
        "path = re.sub('[a-zA-Z\\s._]+$', '', path) #remove unintended file\n",
        "X = []\n",
        "Y = []\n",
        "dirs = os.listdir(path+'/drive/My Drive/ucmerced/UCMerced_LandUse/Images/')\n",
        "dirs=dirs[:]\n",
        "print(len(dirs))\n",
        "'''\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaAMcRQoRH4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = 0\n",
        "for i in dirs:\n",
        "\tn = 0\n",
        "\tcount = 0\n",
        "\tfor pic in glob.glob('/content/drive/My Drive/ucmerced/UCMerced_LandUse/Images/'+i+'/*.tif'):\n",
        "\t\tim = Image.open(pic)\n",
        "\t\tim = np.array(im)\n",
        "\t\tif((im.shape[0]==256) and (im.shape[1] ==256) and n<90): #get only 90 data\n",
        "\t\t\tr = im[:,:,0]\n",
        "\t\t\tg = im[:,:,1]\n",
        "\t\t\tb = im[:,:,2]\n",
        "\t\t\tX.append([r,g,b])\n",
        "\t\t\tY.append([label])\n",
        "\t\t\tn = n + 1\n",
        "\tprint(n)\n",
        "\tlabel = label + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTmBzCghOO8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x_bck=X\n",
        "y_bck=Y\n",
        "\n",
        "\n",
        "X =  np.array(X)\n",
        "Y =  np.array(Y)\n",
        "X = X.reshape(X.shape[0], img_rows, img_cols, 3)\n",
        "X.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LFYk6AVOaDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, 21)\n",
        "y_test = keras.utils.to_categorical(y_test, 21)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-GVSdwAfklB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "import cv2 \n",
        "from scipy.fftpack import dct \n",
        "\n",
        "a=[]\n",
        "b=[]\n",
        "#y = np.random.random((5000, 6, 6, 3))\n",
        "t1 = time.time()\n",
        "a = np.zeros((len(X_train), 256, 256, 3))\n",
        "b = np.zeros((len(X_test), 256, 256, 3))\n",
        "for i in range(len(X_train)):\n",
        "    for j in range(3):\n",
        "        a[i, : , : , j] = cv2.dct(X_train[i, : , : , j])\n",
        "        np.transpose(a, [0, 2, 1, 3])\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    for j in range(3):\n",
        "        a[i, :, :, j] = cv2.dct(X_train[i, :, :, j]) \n",
        "\n",
        "for i in range(0,len(X_test)):\n",
        "    for j in range(3):\n",
        "        b[i, : , : , j] = cv2.dct(X_test[i, : , : , j])\n",
        "        np.transpose(b, [0, 2, 1, 3])\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    for j in range(3):\n",
        "        b[i, :, :, j] = cv2.dct(X_test[i, :, :, j]) \n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igPtn4lQ2G20",
        "colab_type": "text"
      },
      "source": [
        "N_ARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J05M_EVd2Ij8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvg4043k2QJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iN3APuD84UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_cut = a[:,:64,:64,:]\n",
        "b_cut = b[:,:64,:64,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ8ERyLsFc-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(a_cut.shape)\n",
        "print(b_cut.shape)\n",
        "a_cut[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY7kvwQBFRx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_ary = a_cut.reshape((1512,4096,3))\n",
        "b_ary = b_cut.reshape((378,4096,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs3MispeapTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_ary_bckp=a_ary\n",
        "b_aray_bcp=b_ary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM7JsttMIdEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(a_ary.shape)\n",
        "a_ary[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntENNH9l-L_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_a_ary = np.zeros((a_ary.shape[0],4098,3))\n",
        "final_b_ary = np.zeros((b_ary.shape[0],4098,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xReGOVFi9yyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 2                                              #Change n for specific n-ary (n = anything in 2*n)\n",
        "mul=int(a_ary.shape[1])/n\n",
        "avgs = []\n",
        "count=0\n",
        "\n",
        "for j in range(a_ary.shape[0]):\n",
        "    avgR = []\n",
        "    avgG = []\n",
        "    avgB = []\n",
        "    for i in range(n):\n",
        "        l = int(mul*i)\n",
        "        lend = int(mul*(i+1) - 1)\n",
        "        np.sort(a_ary[j,:,0])\n",
        "        np.sort(a_ary[j,:,1])\n",
        "        np.sort(a_ary[j,:,2])\n",
        "        avgR.append(np.average(a_ary[j,l:lend,0]))\n",
        "        avgG.append(np.average(a_ary[j,l:lend,1]))\n",
        "        avgB.append(np.average(a_ary[j,l:lend,2]))\n",
        "    avgR = np.array(avgR)\n",
        "    avgG = np.array(avgG)\n",
        "    avgB = np.array(avgB)\n",
        "    final_a_ary[j,:,0] = np.concatenate((a_ary[j,:,0],avgR))\n",
        "    final_a_ary[j,:,1] = np.concatenate((a_ary[j,:,1],avgG))\n",
        "    final_a_ary[j,:,2] = np.concatenate((a_ary[j,:,2],avgB))\n",
        "\n",
        "mul=int(b_ary.shape[1])/n\n",
        "\n",
        "for j in range(b_ary.shape[0]):\n",
        "    avgR = []\n",
        "    avgG = []\n",
        "    avgB = []\n",
        "    for i in range(n):\n",
        "        l = int(mul*i)\n",
        "        lend = int(mul*(i+1) - 1)\n",
        "        np.sort(b_ary[j,:,0])\n",
        "        np.sort(b_ary[j,:,1])\n",
        "        np.sort(b_ary[j,:,2])\n",
        "        avgR.append(np.average(b_ary[j,l:lend,0]))\n",
        "        avgG.append(np.average(b_ary[j,l:lend,1]))\n",
        "        avgB.append(np.average(b_ary[j,l:lend,2]))\n",
        "    avgR = np.array(avgR)\n",
        "    avgG = np.array(avgG)\n",
        "    avgB = np.array(avgB)\n",
        "    final_b_ary[j,:,0] = np.concatenate((b_ary[j,:,0],avgR))\n",
        "    final_b_ary[j,:,1] = np.concatenate((b_ary[j,:,1],avgG))\n",
        "    final_b_ary[j,:,2] = np.concatenate((b_ary[j,:,2],avgB))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlhtGBgpwjES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_a_ary.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ucIItWQ8nVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_b_ary.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVFSmG1H3o_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D, MaxPooling1D,Embedding\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import plot_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Graphic output\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqARZzJJEx9n",
        "colab_type": "text"
      },
      "source": [
        "**1DCNN ON MATRIX MIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LphFCo9kEw2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3m-MvF5E6Ua",
        "colab": {}
      },
      "source": [
        "model1dM = Sequential()\n",
        "model1dM.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
        "model1dM.add(Conv1D(32, kernel_size=5))    # added new\n",
        "model1dM.add(MaxPooling1D(pool_size=(2)))\n",
        "model1dM.add(Conv1D(64, kernel_size=5))\n",
        "model1dM.add(Conv1D(64, kernel_size=5))    # added new\n",
        "model1dM.add(MaxPooling1D(pool_size=(2)))\n",
        "model1dM.add(Conv1D(128, kernel_size=3))\n",
        "model1dM.add(Conv1D(128, kernel_size=3))    # added new and changed to 128 from 64\n",
        "model1dM.add(MaxPooling1D(pool_size=(2)))\n",
        "model1dM.add(Dropout(0.25))\n",
        "model1dM.add(Flatten())\n",
        "model1dM.add(Dense(128, activation='relu',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
        "model1dM.add(Dropout(0.5))\n",
        "model1dM.add(Dense(21, activation='softmax'))\n",
        "model1dM.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqsmV07bIj18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1dM.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG522cLrJiaU",
        "colab_type": "text"
      },
      "source": [
        "##With smaller model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lJqg5UKxE6Uh",
        "colab": {}
      },
      "source": [
        "model1dM.fit(final_a_ary, y_train, batch_size=50, nb_epoch=200, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs2ru6SmJl9X",
        "colab_type": "text"
      },
      "source": [
        "##With bigger modified model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwq4LmOYJqLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1dM.fit(final_a_ary, y_train, batch_size=50, nb_epoch=200, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brf4w5dFE6Uq",
        "colab": {}
      },
      "source": [
        "loss, acc = model1dM.evaluate(final_b_ary, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvEyN2vXF_-D",
        "colab_type": "text"
      },
      "source": [
        "**BATCH NORMALIZATION ON CONCATED MATRIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isxtNXF0GFRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T1SmuLliGFkk",
        "colab": {}
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# instantiate model\n",
        "modelBNM = Sequential()\n",
        "modelBNM.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
        "modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNM.add(Conv1D(32, kernel_size=5))\n",
        "modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNM.add(Conv1D(64, kernel_size=3))\n",
        "modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNM.add(Dropout(0.25))\n",
        "modelBNM.add(Flatten())\n",
        "# we can think of this chunk as the input layer\n",
        "modelBNM.add(Dense(128,  init='uniform'))\n",
        "modelBNM.add(BatchNormalization())\n",
        "modelBNM.add(Activation('relu'))\n",
        "modelBNM.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the hidden layer    \n",
        "modelBNM.add(Dense(64, init='uniform'))\n",
        "modelBNM.add(BatchNormalization())\n",
        "modelBNM.add(Activation('relu'))\n",
        "modelBNM.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the output layer\n",
        "modelBNM.add(Dense(21, init='uniform'))\n",
        "modelBNM.add(BatchNormalization())\n",
        "modelBNM.add(Activation('softmax'))\n",
        "\n",
        "# setting up the optimization of our weights \n",
        "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "modelBNM.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# running the fitting\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o3eMMfiBGFkq",
        "colab": {}
      },
      "source": [
        "modelBNM.fit(final_a_ary, y_train, batch_size=50, nb_epoch=30, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GcbzxkeIGFkv",
        "colab": {}
      },
      "source": [
        "loss, acc = modelBNM.evaluate(final_b_ary, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpOSdZ7DHYmu",
        "colab_type": "text"
      },
      "source": [
        "**BN with regularization on matrix concat** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1_xJsLSHf4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rxr7yO1hHgJ_",
        "colab": {}
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# instantiate model\n",
        "modelBNrm = Sequential()\n",
        "modelBNrm.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
        "modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNrm.add(Conv1D(32, kernel_size=5))\n",
        "modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNrm.add(Conv1D(64, kernel_size=3))\n",
        "modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNrm.add(Dropout(0.25))\n",
        "modelBNrm.add(Flatten())\n",
        "# we can think of this chunk as the input layer\n",
        "modelBNrm.add(Dense(128,  init='uniform',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
        "modelBNrm.add(BatchNormalization())\n",
        "modelBNrm.add(Activation('relu'))\n",
        "modelBNrm.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the hidden layer    \n",
        "modelBNrm.add(Dense(64, init='uniform',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
        "modelBNrm.add(BatchNormalization())\n",
        "modelBNrm.add(Activation('relu'))\n",
        "modelBNrm.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the output layer\n",
        "modelBNrm.add(Dense(21, init='uniform',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
        "modelBNrm.add(BatchNormalization())\n",
        "modelBNrm.add(Activation('softmax'))\n",
        "\n",
        "# setting up the optimization of our weights \n",
        "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "modelBNrm.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# running the fitting\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nlTLXkUbHgKH",
        "colab": {}
      },
      "source": [
        "modelBNrm.fit(final_a_ary, y_train, batch_size=50, nb_epoch=150, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FQqWMQiwHgKK",
        "colab": {}
      },
      "source": [
        "loss, acc = modelBNrm.evaluate(final_b_ary, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mo8OnblIcJ_",
        "colab_type": "text"
      },
      "source": [
        "BATCH NORMALIZATION ON CNN LAYERS WITH MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8EeQbskmIg33",
        "colab": {}
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# instantiate model\n",
        "modelBNC = Sequential()\n",
        "modelBNC.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNC.add(Conv1D(32, kernel_size=5))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNC.add(Conv1D(64, kernel_size=3))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(MaxPooling1D(pool_size=(2)))\n",
        "modelBNC.add(Dropout(0.25))\n",
        "modelBNC.add(Flatten())\n",
        "# we can think of this chunk as the input layer\n",
        "modelBNC.add(Dense(128, init='uniform'))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(Activation('relu'))\n",
        "modelBNC.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the hidden layer    \n",
        "modelBNC.add(Dense(64, init='uniform'))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(Activation('relu'))\n",
        "modelBNC.add(Dropout(0.5))\n",
        "\n",
        "# we can think of this chunk as the output layer\n",
        "modelBNC.add(Dense(21, init='uniform'))\n",
        "modelBNC.add(BatchNormalization())\n",
        "modelBNC.add(Activation('softmax'))\n",
        "\n",
        "# setting up the optimization of our weights \n",
        "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#modelBNC.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "modelBNC.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# running the fitting\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ks9Zw_B9Ig4A",
        "colab": {}
      },
      "source": [
        "modelBNC.fit(final_a_ary, y_train, batch_size=50, nb_epoch=30, verbose=1, validation_data=(final_b_ary, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "odKwdMviIg4F",
        "colab": {}
      },
      "source": [
        "loss, acc = modelBNC.evaluate(final_b_ary, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}