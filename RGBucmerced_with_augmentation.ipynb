{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RGBucmerced_with_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5-4vtRLMSag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxmUMmm7MXE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATADIR = '/content/drive/My Drive/ucmerced/UCMerced_LandUse/Images/'\n",
        "\n",
        "CATEGORIES = [ 'agricultural',  'airplane',    'baseballdiamond', 'beach',   'buildings',          'chaparral',         'denseresidential',\n",
        "                'forest',        'freeway',     'golfcourse',      'harbor',  'intersection',       'mediumresidential', 'mobilehomepark',\n",
        "                'overpass',      'parkinglot',  'river',           'runway',  'sparseresidential',  'storagetanks',      'tenniscourt' ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_H86fHPMfSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2URG-NMuMoPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image #import Python Image Library\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SqwQD5cNQZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFO-OnseNc4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = os.path.abspath('.cnn.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYoLiNlPNen6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJvCBpm0NjOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = re.sub('[a-zA-Z\\s._]+$', '', path) #remove unintended file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1HXnPmWNo5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyiF2extNsAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dirs = os.listdir(path+'/drive/My Drive/ucmerced/UCMerced_LandUse/Images/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3RFKisIOJ50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 256\n",
        "img_cols = 256\n",
        "num_class = 21\n",
        "path = os.path.abspath('.cnn.py') #absolute path of program\n",
        "path = re.sub('[a-zA-Z\\s._]+$', '', path) #remove unintended file\n",
        "X = []\n",
        "Y = []\n",
        "dirs = os.listdir(path+'/drive/My Drive/ucmerced/UCMerced_LandUse/Images/')\n",
        "dirs=dirs[:]\n",
        "print(len(dirs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaAMcRQoRH4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = 0\n",
        "for i in dirs:\n",
        "\tn = 0\n",
        "\tcount = 0\n",
        "\tfor pic in glob.glob('/content/drive/My Drive/ucmerced/UCMerced_LandUse/Images/'+i+'/*.tif'):\n",
        "\t\tim = Image.open(pic)\n",
        "\t\tim = np.array(im)\n",
        "\t\tif((im.shape[0]==256) and (im.shape[1] ==256) and n<90): #get only 90 data\n",
        "\t\t\tr = im[:,:,0]\n",
        "\t\t\tg = im[:,:,1]\n",
        "\t\t\tb = im[:,:,2]\n",
        "\t\t\tX.append([r,g,b])\n",
        "\t\t\tY.append([label])\n",
        "\t\t\tn = n+1\n",
        "\tprint(n)\n",
        "\tlabel = label + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNLMA0cdXzvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(X))\n",
        "print(len(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R-7A6FIk4zP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_bck=X\n",
        "y_bck=Y\n",
        "\n",
        "\n",
        "X =  np.array(X)\n",
        "Y =  np.array(Y)\n",
        "X = X.reshape(X.shape[0], img_rows, img_cols, 3)\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ_yu4YeSNNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQj8ElwE1DEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LFYk6AVOaDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
        "\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, 21)\n",
        "y_test = keras.utils.to_categorical(y_test, 21)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V5kD_JTOlZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(\"dsa\")\n",
        "print(y_test[0:10])\n",
        "print(\"dsa\")\n",
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkVmVoPcOvjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(21, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjj1mxWpjZH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOYibkOFO1Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=50, nb_epoch=100, verbose=1, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvgEwyc2h1jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_big = Sequential()\n",
        "model_big.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model_big.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model_big.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "model_big.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_big.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_big.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "model_big.add(Dropout(0.25))\n",
        "model_big.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model_big.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "model_big.add(Flatten())\n",
        "model_big.add(Dense(128, activation='relu'))\n",
        "model_big.add(Dropout(0.5))\n",
        "model_big.add(Dense(21, activation='softmax'))\n",
        "model_big.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToWbp-ioi4c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_big.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOQg57GOjt0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_big.fit(X_train, y_train, batch_size=50, nb_epoch=150, verbose=1, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJDw_oS3YNZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc = model_big.evaluate(X_test, y_test, verbose=0)\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcrPB-GqD21P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py5ETAK5LEqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install  split_folders tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDFkuAoXFNKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import split_folders\n",
        "split_folders.ratio(path+'/drive/My Drive/ucmerced/UCMerced_LandUse/Images/', output=path+'/drive/My Drive/ucmerced/UCMerced_LandUse/output/', seed=1337, ratio=(.8, .2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsHYtV9GEN84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import time\n",
        "IMG_SIZE =256 # Replace with the size of your images\n",
        "NB_CHANNELS =3 # 3 for RGB images or 1 for grayscale images\n",
        "BATCH_SIZE = 32# Typical values are 8, 16 or 32\n",
        "NB_TRAIN_IMG = 1680# Replace with the total number training images\n",
        "NB_VALID_IMG = 420# Replace with the total number validation images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8AQc5tQD3J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(IMG_SIZE,IMG_SIZE,NB_CHANNELS),\n",
        "               data_format='channels_last'))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model1.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model1.add(Dropout(0.25))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(128, activation='relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(21, activation='softmax'))\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XypZmhjpTA0A",
        "colab_type": "text"
      },
      "source": [
        "#Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGoONNi1Echd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range = 40,                  \n",
        "    width_shift_range = 0.2,                  \n",
        "    height_shift_range = 0.2,                  \n",
        "    rescale = 1./255,                  \n",
        "    shear_range = 0.2,                  \n",
        "    zoom_range = 0.2,                     \n",
        "    horizontal_flip = True)\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    path+'drive/My Drive/ucmerced/UCMerced_LandUse/output/train',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE),\n",
        "    class_mode='categorical',\n",
        "    batch_size = BATCH_SIZE)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    path+'drive/My Drive/ucmerced/UCMerced_LandUse/output/val',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE),\n",
        "    class_mode='categorical',\n",
        "    batch_size = BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmFgvxGhI1ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = time.time()\n",
        "model_big.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=NB_TRAIN_IMG//BATCH_SIZE,\n",
        "    epochs=300,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=NB_VALID_IMG//BATCH_SIZE)\n",
        "end = time.time()\n",
        "print('Processing time:',(end - start)/60)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}